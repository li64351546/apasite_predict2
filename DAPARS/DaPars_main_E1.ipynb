{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f34f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "from bisect import bisect\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938bd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_now():#return time\n",
    "    curr_time = datetime.datetime.now()\n",
    "    return curr_time.strftime(\"%c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04859ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert_wig_into_bp_coverage\n",
    "\n",
    "def Convert_wig_into_bp_coverage(extracted_coverage,extracted_3UTR_region,strand_info):\n",
    "    bp_coverage = np.zeros(extracted_3UTR_region[-1] - extracted_3UTR_region[0])\n",
    "    relative_start = extracted_3UTR_region[0]\n",
    "    for i in range(len(extracted_coverage)):\n",
    "    \n",
    "        curr_region_start = extracted_3UTR_region[i] - relative_start\n",
    "        curr_region_end = extracted_3UTR_region[i+1] - relative_start\n",
    "        bp_coverage[curr_region_start:curr_region_end] = extracted_coverage[i]\n",
    "    if strand_info == '-':\n",
    "        bp_coverage = bp_coverage[::-1]\n",
    "    \n",
    "    return bp_coverage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f6539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def De_Novo_3UTR_Identification_Loading_Target_Wig_for_TCGA_Multiple_Samples_Main(argv=None):\n",
    "    '''\n",
    "    '''\n",
    "    if len(sys.argv) == 1:\n",
    "        print(\"Please provide the configure file ...\")\n",
    "        exit(1)\n",
    "    cfg_file = sys.argv[1]\n",
    "    print(\"[%s] Start Analysis ...\" % time_now(), file=sys.stderr)\n",
    "    Group1_Tophat_aligned_file,Group2_Tophat_aligned_file,output_directory,Annotated_3UTR_file,Output_result_file,Num_least_in_group1_local,Num_least_in_group2_local,Coverage_cutoff_local,FDR_cutoff_local,Fold_change_cutoff_local,PDUI_cutoff_local = parse_cfgfile(cfg_file)\n",
    "    \n",
    "    num_group_1 = len(Group1_Tophat_aligned_file)\n",
    "    All_Sample_files = Group1_Tophat_aligned_file[:]\n",
    "    All_Sample_files.extend(Group2_Tophat_aligned_file)\n",
    "    \n",
    "    \n",
    "    global Num_least_in_group1\n",
    "    global Num_least_in_group2\n",
    "    global Coverage_cutoff\n",
    "    global FDR_cutoff\n",
    "    global Fold_change_cutoff\n",
    "    global PDUI_cutoff\n",
    "    \n",
    "    if Num_least_in_group1_local != '':\n",
    "        Num_least_in_group1 = float(Num_least_in_group1_local)\n",
    "    if Num_least_in_group2_local != '':\n",
    "        Num_least_in_group2 = float(Num_least_in_group2_local)\n",
    "    if Coverage_cutoff_local != '':\n",
    "        Coverage_cutoff = float(Coverage_cutoff_local)\n",
    "    if FDR_cutoff_local != '':\n",
    "        FDR_cutoff = float(FDR_cutoff_local)\n",
    "    if Fold_change_cutoff_local != '':\n",
    "        Fold_change_cutoff = float(Fold_change_cutoff_local)\n",
    "    if PDUI_cutoff_local != '':\n",
    "        PDUI_cutoff = float(PDUI_cutoff_local)\n",
    "    \n",
    "    \n",
    "\n",
    "    ##Prepare output directory\n",
    "    d = os.path.dirname(output_directory)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)\n",
    "    temp_dir = d+'/tmp/'\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    Output_all_prediction_file = output_directory+Output_result_file+'_result_temp.txt'\n",
    "    Output_result = open(Output_all_prediction_file, 'w')\n",
    "    \n",
    "    num_samples = len(All_Sample_files)\n",
    "    \n",
    "    ##Debug\n",
    "    print(\"[%s] Loading coverage ...\" % time_now(), file=sys.stderr)\n",
    "    All_samples_Target_3UTR_coverages, All_samples_sequencing_depths, UTR_events_dict = Load_Target_Wig_files(All_Sample_files, Annotated_3UTR_file)\n",
    "    All_sample_coverage_weights = All_samples_sequencing_depths/np.mean(All_samples_sequencing_depths)\n",
    "    print(\"[%s] Loading coverage finished ...\" % time_now(), file=sys.stderr)\n",
    "    ##Write the first line\n",
    "    first_line = ['Gene','fit_value','Predicted_Proximal_APA','Loci']\n",
    "    for i in range(num_group_1):\n",
    "        curr_long_exp = 'A_%s_long_exp' % str(i+1)\n",
    "        curr_short_exp = 'A_%s_short_exp' % str(i+1)\n",
    "        curr_ratio ='A_%s_PDUI' % str(i+1)\n",
    "        first_line.extend([curr_long_exp,curr_short_exp,curr_ratio])\n",
    "    for i in range(num_samples - num_group_1):\n",
    "        curr_long_exp = 'B_%s_long_exp' % str(i+1)\n",
    "        curr_short_exp = 'B_%s_short_exp' % str(i+1)\n",
    "        curr_ratio ='B_%s_PDUI' % str(i+1)\n",
    "        first_line.extend([curr_long_exp,curr_short_exp,curr_ratio])\n",
    "    first_line.append('PDUI_Group_diff')\n",
    "    \n",
    "    Output_result.writelines('\\t'.join(first_line) + '\\n')\n",
    "    \n",
    "    \n",
    "    for curr_3UTR_id in UTR_events_dict:\n",
    "        curr_3UTR_structure = UTR_events_dict[curr_3UTR_id]\n",
    "        region_start = curr_3UTR_structure[1]\n",
    "        region_end   = curr_3UTR_structure[2]\n",
    "        curr_strand  = curr_3UTR_structure[-2]\n",
    "        UTR_pos = curr_3UTR_structure[-1]\n",
    "        if curr_3UTR_id in All_samples_Target_3UTR_coverages:\n",
    "            curr_3UTR_coverage_wig = All_samples_Target_3UTR_coverages[curr_3UTR_id]\n",
    "            curr_3UTR_all_samples_bp_coverage = []\n",
    "            for curr_sample_curr_3UTR_coverage_wig in curr_3UTR_coverage_wig: \n",
    "                curr_3UTR_curr_sample_bp_coverage = Convert_wig_into_bp_coverage(curr_sample_curr_3UTR_coverage_wig[0],curr_sample_curr_3UTR_coverage_wig[1],curr_strand)\n",
    "                curr_3UTR_all_samples_bp_coverage.append(curr_3UTR_curr_sample_bp_coverage)\n",
    "            \n",
    "            select_mean_squared_error,selcted_break_point,UTR_abundances = De_Novo_3UTR_Coverage_estimation_Genome_for_TCGA_multiple_samples(curr_3UTR_all_samples_bp_coverage, region_start, region_end,curr_strand,All_sample_coverage_weights)\n",
    "            \n",
    "            \n",
    "            if str(select_mean_squared_error) != \"Na\":\n",
    "                Long_3UTR_exp_all = np.array(UTR_abundances[0])\n",
    "                Short_3UTR_exp_all = np.array(UTR_abundances[1])\n",
    "                num_non_zero = sum((Long_3UTR_exp_all + Short_3UTR_exp_all)>0)\n",
    "                if num_non_zero == num_samples:\n",
    "                    All_Long_inclusion_ratios = []\n",
    "                    line_write = [curr_3UTR_id, \"%.1f\" % select_mean_squared_error, str(selcted_break_point), UTR_pos]\n",
    "                    for i in range(num_samples):\n",
    "                        curr_sample_ratio = float(UTR_abundances[0][i])/(float(UTR_abundances[0][i]) + float(UTR_abundances[1][i]))##long 3'UTR percentage\n",
    "                        All_Long_inclusion_ratios.append(curr_sample_ratio)\n",
    "                        line_write.append(\"%.2f\" % UTR_abundances[0][i])\n",
    "                        line_write.append(\"%.2f\" % UTR_abundances[1][i])\n",
    "                        line_write.append(\"%.2f\" % curr_sample_ratio)\n",
    "                    \n",
    "                    Group1_IR = All_Long_inclusion_ratios[:num_group_1]\n",
    "                    Group2_IR = All_Long_inclusion_ratios[num_group_1:]\n",
    "                    inclusion_ratio_Group_diff = np.mean(np.array(Group1_IR)) - np.mean(np.array(Group2_IR))\n",
    "                    \n",
    "                    line_write.append(\"%.2f\" % inclusion_ratio_Group_diff)\n",
    "                    \n",
    "                    Output_result.writelines( '\\t'.join(line_write)+'\\n')\n",
    "        \n",
    "    Output_result.close()\n",
    "    \n",
    "    print(\"[%s] Filtering the result ...\" % time_now(), file=sys.stderr)\n",
    "    \n",
    "    Output_Motif_filtered_result_file = output_directory+Output_result_file+'_All_Prediction_Results.txt'\n",
    "    #UTR_APA_Result_filtering(Output_all_prediction_file,Genome_seq_fasta,Output_Motif_filtered_result_file)\n",
    "    \n",
    "    DaPars_Filtering(Output_all_prediction_file, num_samples,num_group_1 ,Output_Motif_filtered_result_file)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        os.remove(Output_all_prediction_file)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        os.rmdir(temp_dir)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"[%s] Finished!\" % time_now(), file=sys.stderr)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca2eeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "li2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
